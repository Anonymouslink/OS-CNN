{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# thre fist part is versification of Pytorch FCN & ResNet implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "currentdir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.append(parentdir)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from os.path import dirname\n",
    "import numpy as np\n",
    "from utils.log_manager import eval_condition, eval_model\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from utils.dataloader.TSC_data_loader import TSC_data_loader\n",
    "from Classifiers.FCN import FCN as Torch_FCN\n",
    "\n",
    "Max_epoch = 2000\n",
    "print_result_every_x_epoch = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FiftyWords\n",
      "code is running on:  cuda:0\n",
      "270 tensor(50, device='cuda:0')\n",
      "199 4.171777725219727 0.00025\n",
      "train_acc=\t 0.9555555555555556 \t test_acc=\t 0.643956043956044 \t loss=\t 4.171777725219727\n",
      "399 0.1811048984527588 0.000125\n",
      "train_acc=\t 0.9977777777777778 \t test_acc=\t 0.6461538461538462 \t loss=\t 0.1811048984527588\n",
      "599 1.843912959098816 0.0001\n",
      "train_acc=\t 0.9844444444444445 \t test_acc=\t 0.6043956043956044 \t loss=\t 1.843912959098816\n",
      "799 0.3334866166114807 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.6395604395604395 \t loss=\t 0.3334866166114807\n",
      "999 0.35695481300354004 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.6681318681318681 \t loss=\t 0.35695481300354004\n",
      "1199 2.666208505630493 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.6681318681318681 \t loss=\t 2.666208505630493\n",
      "1399 0.2539825439453125 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.6351648351648351 \t loss=\t 0.2539825439453125\n",
      "1599 0.6584628820419312 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.6461538461538462 \t loss=\t 0.6584628820419312\n",
      "1799 0.387653112411499 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.6571428571428571 \t loss=\t 0.387653112411499\n",
      "1999 0.2789313793182373 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.6373626373626373 \t loss=\t 0.2789313793182373\n",
      "FiftyWords 0.6373626373626373\n"
     ]
    }
   ],
   "source": [
    "dataset_name_list = [\n",
    "    'FiftyWords',  # 62.7(6.1)\n",
    "]\n",
    "# check our result with result here \n",
    "# https://github.com/hfawaz/dl-4-tsc/blob/master/results/results-uea-avg-std.csv\n",
    "\n",
    "dataset_path = dirname(parentdir+\"./Example_Datasets/UCRArchive_2018/\")\n",
    "for dataset_name in dataset_name_list:\n",
    "    print(dataset_name)\n",
    "    X_train, y_train, X_test, y_test = TSC_data_loader(dataset_path, dataset_name)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('code is running on: ', device)\n",
    "    X_train = torch.from_numpy(X_train)\n",
    "    X_train.requires_grad = False\n",
    "    X_train = X_train.unsqueeze_(1).to(device)\n",
    "    y_train = torch.from_numpy(y_train).to(device)\n",
    "    X_test = torch.from_numpy(X_test)\n",
    "    X_test.requires_grad = False\n",
    "    X_test = X_test.unsqueeze_(1).to(device)\n",
    "    y_test = torch.from_numpy(y_test).to(device)\n",
    "\n",
    "    input_shape = X_train.shape[-1]\n",
    "    n_class = max(y_train) + 1\n",
    "    print(input_shape, n_class)\n",
    "    \n",
    "    \n",
    "    torch_FCN = Torch_FCN(input_shape, n_class.item()).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(torch_FCN.parameters())\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience= 50, min_lr=0.0001)\n",
    "    torch_FCN.train()\n",
    "\n",
    "    dataset = TensorDataset(X_train, y_train)\n",
    "    batch_size = 16\n",
    "    loader = DataLoader(dataset, batch_size=int(min(X_train.shape[0] / 10, batch_size)), shuffle=True)\n",
    "\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=int(min(X_train.shape[0] / 10, batch_size)), shuffle=False)\n",
    "\n",
    "    for i in range(Max_epoch):\n",
    "        for sample in loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_predict = torch_FCN(sample[0])\n",
    "            output = criterion(y_predict, sample[1])\n",
    "            output.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step(output)\n",
    "\n",
    "        if eval_condition(i,print_result_every_x_epoch):\n",
    "            for param_group in optimizer.param_groups:\n",
    "                print(i, output.item(), param_group['lr'])\n",
    "            torch_FCN.eval()\n",
    "            acc_train = eval_model(torch_FCN, loader)\n",
    "            acc_test = eval_model(torch_FCN, test_loader)\n",
    "            torch_FCN.train()\n",
    "            print('train_acc=\\t', acc_train, '\\t test_acc=\\t', acc_test,'\\t loss=\\t', output.item())\n",
    "\n",
    "    torch_FCN.eval()\n",
    "    acc_test = eval_model(torch_FCN, test_loader)\n",
    "    torch.cuda.empty_cache()\n",
    "    print(dataset_name,acc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FiftyWords\n",
      "code is running on:  cuda:0\n",
      "270 tensor(50, device='cuda:0')\n",
      "199 1.6963386535644531 0.001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.7186813186813187 \t loss=\t 1.6963386535644531\n",
      "399 0.299480140209198 0.00025\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.734065934065934 \t loss=\t 0.299480140209198\n",
      "599 0.5820592641830444 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.7208791208791209 \t loss=\t 0.5820592641830444\n",
      "799 0.8479273319244385 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.7142857142857143 \t loss=\t 0.8479273319244385\n",
      "999 1.4371581077575684 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.7274725274725274 \t loss=\t 1.4371581077575684\n",
      "1199 0.045929908752441406 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.7450549450549451 \t loss=\t 0.045929908752441406\n",
      "1399 0.021345853805541992 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.7274725274725274 \t loss=\t 0.021345853805541992\n",
      "1599 0.05151724815368652 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.7032967032967034 \t loss=\t 0.05151724815368652\n",
      "1799 0.25116491317749023 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.7296703296703296 \t loss=\t 0.25116491317749023\n",
      "1999 0.137131929397583 0.0001\n",
      "train_acc=\t 1.0 \t test_acc=\t 0.7274725274725274 \t loss=\t 0.137131929397583\n",
      "FiftyWords 0.7274725274725274\n"
     ]
    }
   ],
   "source": [
    "from Classifiers.ResNet import ResNet as Torch_ResNet\n",
    "\n",
    "print_result_every_x_epoch = 200\n",
    "\n",
    "dataset_name_list = [\n",
    "    'FiftyWords',  # 74.0(1.5)\n",
    "]\n",
    "# check our result with result here \n",
    "# https://github.com/hfawaz/dl-4-tsc/blob/master/results/results-uea-avg-std.csv\n",
    "\n",
    "dataset_path = dirname(parentdir+\"./Example_Datasets/UCRArchive_2018/\")\n",
    "for dataset_name in dataset_name_list:\n",
    "    print(dataset_name)\n",
    "    X_train, y_train, X_test, y_test = TSC_data_loader(dataset_path, dataset_name)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('code is running on: ', device)\n",
    "    X_train = torch.from_numpy(X_train)\n",
    "    X_train.requires_grad = False\n",
    "    X_train = X_train.unsqueeze_(1).to(device)\n",
    "    y_train = torch.from_numpy(y_train).to(device)\n",
    "    X_test = torch.from_numpy(X_test)\n",
    "    X_test.requires_grad = False\n",
    "    X_test = X_test.unsqueeze_(1).to(device)\n",
    "    y_test = torch.from_numpy(y_test).to(device)\n",
    "\n",
    "    input_shape = X_train.shape[-1]\n",
    "    n_class = max(y_train) + 1\n",
    "    print(input_shape, n_class)\n",
    "    \n",
    "    \n",
    "    Torch_ResNet = Torch_ResNet(input_shape, n_class.item()).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(Torch_ResNet.parameters())\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience= 50, min_lr=0.0001)\n",
    "    Torch_ResNet.train()\n",
    "\n",
    "    dataset = TensorDataset(X_train, y_train)\n",
    "    batch_size = 16\n",
    "    loader = DataLoader(dataset, batch_size=int(min(X_train.shape[0] / 10, batch_size)), shuffle=True)\n",
    "\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=int(min(X_train.shape[0] / 10, batch_size)), shuffle=False)\n",
    "\n",
    "    for i in range(Max_epoch):\n",
    "        for sample in loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_predict = Torch_ResNet(sample[0])\n",
    "            output = criterion(y_predict, sample[1])\n",
    "            output.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step(output)\n",
    "\n",
    "        if eval_condition(i,print_result_every_x_epoch):\n",
    "            for param_group in optimizer.param_groups:\n",
    "                print(i, output.item(), param_group['lr'])\n",
    "            Torch_ResNet.eval()\n",
    "            acc_train = eval_model(Torch_ResNet, loader)\n",
    "            acc_test = eval_model(Torch_ResNet, test_loader)\n",
    "            Torch_ResNet.train()\n",
    "            print('train_acc=\\t', acc_train, '\\t test_acc=\\t', acc_test,'\\t loss=\\t', output.item())\n",
    "\n",
    "    Torch_ResNet.eval()\n",
    "    acc_test = eval_model(Torch_ResNet, test_loader)\n",
    "    torch.cuda.empty_cache()\n",
    "    print(dataset_name,acc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
